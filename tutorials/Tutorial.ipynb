{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyasifred/TW-FR-MT/blob/main/tutorials/Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJwW9M02k9q6"
      },
      "source": [
        "# Twi-French Machine Translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a0_C_-6fX3X",
        "outputId": "da6559bd-c03a-497a-c547-c311c7e0bb89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENLubxfsGeua"
      },
      "source": [
        "\n",
        "In this tutorial, we will illustrate how to\n",
        " \n",
        "1. fine-tune the pre-trained [Helsinki-NLP/opus-mt-tw-fr](https://huggingface.co/Helsinki-NLP/opus-mt-tw-fr) from the [OPUS-MT](https://opus.nlpl.eu/Opus-MT/) repository for machine translation of Twi (the local Ghanaian language) to French.\n",
        " \n",
        "2. perform translations with the fine-tuned OPUS-MT model.\n",
        "3. estimate the machine translation quality with the [BLEU score](https://aclanthology.org/P02-1040.pdf), AzunreBLEU score, the [TER score](https://aclanthology.org/2006.amta-papers.25/) and the [SacreBLEU score](https://aclanthology.org/W18-6319.pdf).\n",
        "\n",
        "*** The AzunreBLEU score is a variant of the BLEU score that was used for evaluating machine translation quality in the paper [English-Twi Parallel Corpus for Machine Translation](https://arxiv.org/pdf/2103.15625.pdf) indicating that the focus is on \"adequacy\" instead of \"fluency\" in the translations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3904ZdrhmuRD"
      },
      "source": [
        "## [Optional] Download already-fine-tuned Twi models.\n",
        "\n",
        "\n",
        "Fine-tuned Twi OPUS-MT models can be downloaded from [Google Drive](https://drive.google.com/drive/folders/13irIvPsqnryP_NJ5y6PneFKrQDJs5Qm6?usp=sharing). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0pZ6duaM4PX"
      },
      "source": [
        "\n",
        "This tutorial uses GPU; to use GPU, please go to EDIT on the menu bar, notebook settings, and choose GPU for the hardware accelerator, then save."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeRghrAZOmIP"
      },
      "source": [
        "## Clone TW-FR-MT Github Repository\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRcZA-ETOuBO",
        "outputId": "7dbd2af1-8381-4a59-9677-72da67406fdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TW-FR-MT'...\n",
            "remote: Enumerating objects: 219, done.\u001b[K\n",
            "remote: Counting objects: 100% (219/219), done.\u001b[K\n",
            "remote: Compressing objects: 100% (158/158), done.\u001b[K\n",
            "remote: Total 219 (delta 110), reused 145 (delta 58), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (219/219), 1.10 MiB | 9.15 MiB/s, done.\n",
            "Resolving deltas: 100% (110/110), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/gyasifred/TW-FR-MT.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV5bu-yzPhkR",
        "outputId": "7b575d6a-f4cd-4aa4-9762-ab8e05528cba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TW-FR-MT\n"
          ]
        }
      ],
      "source": [
        "%cd TW-FR-MT/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amKuO9lncd2j",
        "outputId": "b07e1ab5-e006-4439-b272-39a5f203f0d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__init__.py  MT_systems  requirements.txt  TW_FR_EN_corpus\n",
            "LICENSE      README.md\t tutorials\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZTEFZFnNlnT"
      },
      "source": [
        "## Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiI0BgPsMDbs",
        "outputId": "fcb71862-3c05-427a-9962-9def91731d40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-learn==1.0.2 (from -r requirements.txt (line 1))\n",
            "  Downloading scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers (from -r requirements.txt (line 2))\n",
            "  Downloading transformers-4.30.1-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece (from -r requirements.txt (line 3))\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate==0.3.0 (from -r requirements.txt (line 4))\n",
            "  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting googletrans==3.1.0a0 (from -r requirements.txt (line 5))\n",
            "  Downloading googletrans-3.1.0a0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate (from -r requirements.txt (line 6))\n",
            "  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu==2.3.1 (from -r requirements.txt (line 7))\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nltk==3.7 (from -r requirements.txt (line 8))\n",
            "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses==0.0.53 (from -r requirements.txt (line 9))\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2->-r requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2->-r requirements.txt (line 1)) (1.10.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2->-r requirements.txt (line 1)) (3.1.0)\n",
            "Collecting datasets>=2.0.0 (from evaluate==0.3.0->-r requirements.txt (line 4))\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from evaluate==0.3.0->-r requirements.txt (line 4))\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0->-r requirements.txt (line 4)) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0->-r requirements.txt (line 4)) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0->-r requirements.txt (line 4)) (4.65.0)\n",
            "Collecting xxhash (from evaluate==0.3.0->-r requirements.txt (line 4))\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from evaluate==0.3.0->-r requirements.txt (line 4))\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0->-r requirements.txt (line 4)) (2023.4.0)\n",
            "Collecting huggingface-hub>=0.7.0 (from evaluate==0.3.0->-r requirements.txt (line 4))\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0->-r requirements.txt (line 4)) (23.1)\n",
            "Collecting responses<0.19 (from evaluate==0.3.0->-r requirements.txt (line 4))\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting httpx==0.13.3 (from googletrans==3.1.0a0->-r requirements.txt (line 5))\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu==2.3.1->-r requirements.txt (line 7))\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu==2.3.1->-r requirements.txt (line 7)) (2022.10.31)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu==2.3.1->-r requirements.txt (line 7)) (0.8.10)\n",
            "Collecting colorama (from sacrebleu==2.3.1->-r requirements.txt (line 7))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu==2.3.1->-r requirements.txt (line 7)) (4.9.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk==3.7->-r requirements.txt (line 8)) (8.1.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.53->-r requirements.txt (line 9)) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0->-r requirements.txt (line 5)) (2022.12.7)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==3.1.0a0->-r requirements.txt (line 5))\n",
            "  Downloading hstspreload-2023.1.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0->-r requirements.txt (line 5)) (1.3.0)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==3.1.0a0->-r requirements.txt (line 5))\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==2.* (from httpx==0.13.3->googletrans==3.1.0a0->-r requirements.txt (line 5))\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==3.1.0a0->-r requirements.txt (line 5))\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==3.1.0a0->-r requirements.txt (line 5))\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0->-r requirements.txt (line 5))\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0->-r requirements.txt (line 5))\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0->-r requirements.txt (line 5))\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0->-r requirements.txt (line 5))\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 2)) (3.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 2)) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers->-r requirements.txt (line 2))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m125.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers->-r requirements.txt (line 2))\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 6)) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 6)) (2.0.1+cu118)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.3.0->-r requirements.txt (line 4)) (9.0.0)\n",
            "Collecting aiohttp (from datasets>=2.0.0->evaluate==0.3.0->-r requirements.txt (line 4))\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate==0.3.0->-r requirements.txt (line 4)) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate==0.3.0->-r requirements.txt (line 4)) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate==0.3.0->-r requirements.txt (line 4)) (2.0.12)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate->-r requirements.txt (line 6)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate->-r requirements.txt (line 6)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate->-r requirements.txt (line 6)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate->-r requirements.txt (line 6)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate->-r requirements.txt (line 6)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate->-r requirements.txt (line 6)) (16.0.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate==0.3.0->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate==0.3.0->-r requirements.txt (line 4)) (2022.7.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.3.0->-r requirements.txt (line 4)) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.0.0->evaluate==0.3.0->-r requirements.txt (line 4))\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets>=2.0.0->evaluate==0.3.0->-r requirements.txt (line 4))\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets>=2.0.0->evaluate==0.3.0->-r requirements.txt (line 4))\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.0.0->evaluate==0.3.0->-r requirements.txt (line 4))\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.0.0->evaluate==0.3.0->-r requirements.txt (line 4))\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate->-r requirements.txt (line 6)) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate->-r requirements.txt (line 6)) (1.3.0)\n",
            "Building wheels for collected packages: googletrans, sacremoses\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.1.0a0-py3-none-any.whl size=16352 sha256=e1b3f4ddaac69c4c9b657d96d7665eadf7e47c3d4771c79d554dcc3685a3eb06\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/5d/3c/8477d0af4ca2b8b1308812c09f1930863caeebc762fe265a95\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=c86eb703b00a9448b08e62a258221d70728fd71e108fb3759e1ffc231bac8ac9\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "Successfully built googletrans sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, rfc3986, hyperframe, hpack, h11, chardet, xxhash, sacremoses, portalocker, nltk, multidict, idna, hstspreload, h2, frozenlist, dill, colorama, async-timeout, yarl, scikit-learn, sacrebleu, multiprocess, httpcore, aiosignal, responses, huggingface-hub, httpx, aiohttp, transformers, googletrans, datasets, evaluate, accelerate\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 4.0.0\n",
            "    Uninstalling chardet-4.0.0:\n",
            "      Successfully uninstalled chardet-4.0.0\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "Successfully installed accelerate-0.20.3 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 chardet-3.0.4 colorama-0.4.6 datasets-2.12.0 dill-0.3.6 evaluate-0.3.0 frozenlist-1.3.3 googletrans-3.1.0a0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2023.1.1 httpcore-0.9.1 httpx-0.13.3 huggingface-hub-0.15.1 hyperframe-5.2.0 idna-2.10 multidict-6.0.4 multiprocess-0.70.14 nltk-3.7 portalocker-2.7.0 responses-0.18.0 rfc3986-1.5.0 sacrebleu-2.3.1 sacremoses-0.0.53 safetensors-0.3.1 scikit-learn-1.0.2 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.30.1 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZMyGaybmVwJ"
      },
      "source": [
        "## Training, Validation, and Test sets\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW8C5_aVpJ6A"
      },
      "source": [
        "\n",
        "Get the help message for how to use any script by passing the -h flag."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TN3gLXggmUZa"
      },
      "outputs": [],
      "source": [
        "#!python /content/TW-FR-MT/TW_FR_EN_corpus/scripts/train_test_split.py -h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph4P473kocRI",
        "outputId": "0c2d89e8-9ac4-4a24-90fd-45baf1128c4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUCCESS\n"
          ]
        }
      ],
      "source": [
        "!python /content/TW-FR-MT/TW_FR_EN_corpus/scripts/train_test_split.py \\\n",
        "/content/TW-FR-MT/TW_FR_EN_corpus/data/total/total_tw.txt \\\n",
        "/content/TW-FR-MT/TW_FR_EN_corpus/data/total/total_en.txt \\\n",
        "/content/TW-FR-MT/TW_FR_EN_corpus/data/total/total_fr.txt \\\n",
        "--id_tw tw \\\n",
        "--id_en en \\\n",
        "--id_fr fr \\\n",
        "--train_ouput_path /content/TW-FR-MT/TW_FR_EN_corpus/data/training \\\n",
        "--test_ouput_path /content/TW-FR-MT/TW_FR_EN_corpus/data/test \\\n",
        "--val_ouput_path  /content/TW-FR-MT/TW_FR_EN_corpus/data/validation \\\n",
        "--val_set True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvWgNDRXQPuw"
      },
      "source": [
        "## Fine-tuning the OPUS-MT Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5iEqSaRpNzVa"
      },
      "outputs": [],
      "source": [
        "#!python /content/TW-FR-MT/MT_systems/opus/fine_tune_opus.py -h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILIBv64VSA7Y",
        "outputId": "f046fc1a-06ea-4b7a-a1c0-9c823d7d58f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-10 16:14:51.612006: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "MODEL PATH: /content/drive/MyDrive/MT\n",
            "FINED-TURNED MODEL NAME: OPUS-mt-tw-fr-tuned-1\n",
            "================\n",
            "Downloading builder script: 100% 8.15k/8.15k [00:00<00:00, 8.12MB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 42.0/42.0 [00:00<00:00, 269kB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 1.38k/1.38k [00:00<00:00, 7.80MB/s]\n",
            "Downloading (…)olve/main/source.spm: 100% 788k/788k [00:00<00:00, 12.9MB/s]\n",
            "Downloading (…)olve/main/target.spm: 100% 845k/845k [00:00<00:00, 13.5MB/s]\n",
            "Downloading (…)olve/main/vocab.json: 100% 1.44M/1.44M [00:00<00:00, 12.6MB/s]\n",
            "Downloading pytorch_model.bin: 100% 302M/302M [00:05<00:00, 52.6MB/s]\n",
            "Downloading (…)neration_config.json: 100% 293/293 [00:00<00:00, 1.93MB/s]\n",
            "  4% 1071/25704 [01:18<26:42, 15.37it/s]\n",
            "  0% 0/134 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 1/134 [00:00<00:40,  3.31it/s]\u001b[A\n",
            "  1% 2/134 [00:00<00:38,  3.39it/s]\u001b[A\n",
            "  2% 3/134 [00:00<00:34,  3.81it/s]\u001b[A\n",
            "  3% 4/134 [00:01<00:35,  3.61it/s]\u001b[A\n",
            "  4% 5/134 [00:01<00:33,  3.84it/s]\u001b[A\n",
            "  4% 6/134 [00:01<00:32,  3.95it/s]\u001b[A\n",
            "  5% 7/134 [00:01<00:36,  3.44it/s]\u001b[A\n",
            "  6% 8/134 [00:02<00:35,  3.56it/s]\u001b[A\n",
            "  7% 9/134 [00:02<00:43,  2.86it/s]\u001b[A\n",
            "  7% 10/134 [00:03<00:42,  2.90it/s]\u001b[A\n",
            "  8% 11/134 [00:03<00:45,  2.71it/s]\u001b[A\n",
            "  9% 12/134 [00:03<00:42,  2.85it/s]\u001b[A\n",
            " 10% 13/134 [00:04<00:41,  2.95it/s]\u001b[A\n",
            " 10% 14/134 [00:04<00:42,  2.85it/s]\u001b[A\n",
            " 11% 15/134 [00:04<00:43,  2.71it/s]\u001b[A\n",
            " 12% 16/134 [00:05<00:47,  2.47it/s]\u001b[A\n",
            " 13% 17/134 [00:05<00:49,  2.38it/s]\u001b[A\n",
            " 13% 18/134 [00:06<00:53,  2.18it/s]\u001b[A\n",
            " 14% 19/134 [00:06<00:49,  2.34it/s]\u001b[A\n",
            " 15% 20/134 [00:08<01:23,  1.37it/s]\u001b[A\n",
            " 16% 21/134 [00:08<01:05,  1.74it/s]\u001b[A\n",
            " 16% 22/134 [00:08<00:54,  2.07it/s]\u001b[A\n",
            " 17% 23/134 [00:08<00:46,  2.37it/s]\u001b[A\n",
            " 18% 24/134 [00:09<00:40,  2.73it/s]\u001b[A\n",
            " 19% 25/134 [00:09<00:37,  2.92it/s]\u001b[A\n",
            " 19% 26/134 [00:09<00:35,  3.02it/s]\u001b[A\n",
            " 20% 27/134 [00:10<00:34,  3.07it/s]\u001b[A\n",
            " 21% 28/134 [00:10<00:34,  3.04it/s]\u001b[A\n",
            " 22% 29/134 [00:10<00:34,  3.06it/s]\u001b[A\n",
            " 22% 30/134 [00:11<00:33,  3.08it/s]\u001b[A\n",
            " 23% 31/134 [00:11<00:33,  3.05it/s]\u001b[A\n",
            " 24% 32/134 [00:11<00:33,  3.07it/s]\u001b[A\n",
            " 25% 33/134 [00:11<00:31,  3.16it/s]\u001b[A\n",
            " 25% 34/134 [00:12<00:32,  3.11it/s]\u001b[A"
          ]
        }
      ],
      "source": [
        "!python /content/TW-FR-MT/MT_systems/opus/fine_tune_opus.py \\\n",
        "Helsinki-NLP/opus-mt-tw-fr \\\n",
        "/content/TW-FR-MT/TW_FR_EN_corpus/data/training/train_tw.txt \\\n",
        "/content/TW-FR-MT/TW_FR_EN_corpus/data/training/train_fr.txt \\\n",
        "/content/TW-FR-MT/TW_FR_EN_corpus/data/validation/val_tw.txt \\\n",
        "/content/TW-FR-MT/TW_FR_EN_corpus/data/validation/val_fr.txt \\\n",
        "tw \\\n",
        "fr \\\n",
        "OPUS-mt-tw-fr-tuned-1 \\\n",
        "--max_length 128 \\\n",
        "--batch_size 8 \\\n",
        "--epoch 24 \\\n",
        "--warmup_steps 10 \\\n",
        "--savedir /content/drive/MyDrive/MT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djayZAn5dRVY"
      },
      "source": [
        "\n",
        "## Translate with the Fine-tuned OPUS-MT Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlhS7RyuS5nR"
      },
      "outputs": [],
      "source": [
        "!python /content/TW-FR-MT/MT_systems/opus/opus_direct_translate.py \\\n",
        "/content/drive/MyDrive/MT/OPUS-mt-tw-fr-tuned-1 \\\n",
        "/content/TW-FR-MT/TW_FR_EN_corpus/data/test/test_tw.txt \\\n",
        "--output_name tw-fr-opus-translate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoCHwP4Ulx7O"
      },
      "source": [
        "## Evaluate the Translation Quality of the OPUS-MT Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDIf-KGfmDc-"
      },
      "source": [
        "### BLEU Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUxpm6UJeaV4"
      },
      "outputs": [],
      "source": [
        "!python /content/TW-FR-MT/MT_systems/evalution_scripts/get_bleu.py \\\n",
        "tw-fr-opus-translate \\\n",
        "/content/TW-FR-MT/TW_FR_EN_corpus/data/test/test_fr.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhVP-G9lnSXK"
      },
      "source": [
        "### AzunreBLEU Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dr89NYffgxyA"
      },
      "outputs": [],
      "source": [
        "!python /content/TW-FR-MT/MT_systems/evalution_scripts/get_bleu.py \\\n",
        "tw-fr-opus-translate \\\n",
        "/content/TW-FR-MT/TW_FR_EN_corpus/data/test/test_fr.txt \\\n",
        "--azunre True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcpCH72vnmWg"
      },
      "source": [
        "### SacreBLEU Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ue3AqnKknoKG"
      },
      "outputs": [],
      "source": [
        "!python /content/TW-FR-MT/MT_systems/evalution_scripts/get_sacrebleu.py \\\n",
        "tw-fr-opus-translate \\\n",
        "/content/TW-FR-MT/TW_FR_EN_corpus/data/test/test_fr.txt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7KBgNk4hIAS"
      },
      "source": [
        "TER Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FY7_pSz0hGfp"
      },
      "outputs": [],
      "source": [
        "!python /content/TW-FR-MT/MT_systems/evalution_scripts/ter.py \\\n",
        "tw-fr-opus-translate \\\n",
        "/content/TW-FR-MT/TW_FR_EN_corpus/data/test/test_fr.txt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13wPv6RZtIvc"
      },
      "source": [
        "## Pre-trained OPUST-MT model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Do-tAKhltHgP"
      },
      "outputs": [],
      "source": [
        "!python /content/TW-FR-MT/MT_systems/opus/opus_direct_translate.py \\\n",
        "Helsinki-NLP/opus-mt-tw-fr \\\n",
        "/content/TW-FR-MT/TW_FR_EN_corpus/data/test/test_tw.txt \\\n",
        "--output_name tw-fr-opus-translate-pretrained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRkaQKR3tisK"
      },
      "outputs": [],
      "source": [
        "!python /content/TW-FR-MT/MT_systems/evalution_scripts/get_bleu.py \\\n",
        "tw-fr-opus-translate-pretrained \\\n",
        "/content/TW-FR-MT/TW_FR_EN_corpus/data/test/un_test_fr.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUSBsk9ntixo"
      },
      "outputs": [],
      "source": [
        "!python /content/TW-FR-MT/MT_systems/evalution_scripts/get_bleu.py \\\n",
        "tw-fr-opus-translate-pretrained \\\n",
        "/content/TW-FR-MT/TW_FR_EN_corpus/data/test/un_test_fr.txt \\\n",
        "--azunre True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srAI9W7ct4P7"
      },
      "outputs": [],
      "source": [
        "!python /content/TW-FR-MT/MT_systems/evalution_scripts/get_sacrebleu.py \\\n",
        "tw-fr-opus-translate-pretrained \\\n",
        "/content/TW-FR-MT/TW_FR_EN_corpus/data/test/un_test_fr.txt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf7nnCbjh5se"
      },
      "source": [
        "TER score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeZna0dkh9z4"
      },
      "outputs": [],
      "source": [
        "!python /content/TW-FR-MT/MT_systems/evalution_scripts/ter.py \\\n",
        "tw-fr-opus-translate-pretrained \\\n",
        "/content/TW-FR-MT/TW_FR_EN_corpus/data/test/un_test_fr.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA1Ayzk4obit"
      },
      "source": [
        "## Google Translate API\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NFeFgNIxRgd"
      },
      "source": [
        "### Translate with the Google Translate API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jx0c5k8mn-EU"
      },
      "outputs": [],
      "source": [
        "! python /content/TW-FR-MT/MT_systems/Google_MT/googleAPIdirect_translate.py \\\n",
        "/content/TW-FR-MT/TW_FR_EN_corpus/data/test/test_tw.txt \\\n",
        "ak\\\n",
        "fr\\\n",
        "--output_name twi-fr-google-translate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvllXWvVslf4"
      },
      "source": [
        "\n",
        "### Evaluate the Translation Quality of the Google API Translation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQPgMVajwxy0"
      },
      "source": [
        "#### BLEU Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpJH6RSurTvJ"
      },
      "outputs": [],
      "source": [
        "!python /content/TW-FR-MT/MT_systems/evalution_scripts/get_bleu.py \\\n",
        "twi-fr-google-translate \\\n",
        "/content/TW-FR-MT/TW_FR_EN_corpus/data/test/un_test_fr.txt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os7aj-_1xgI3"
      },
      "source": [
        "#### AzunreBLEU Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNjtLIcmq_YL"
      },
      "outputs": [],
      "source": [
        "!python /content/TW-FR-MT/MT_systems/evalution_scripts/get_bleu.py \\\n",
        "twi-fr-google-translate \\\n",
        "/content/TW-FR-MT/TW_FR_EN_corpus/data/test/un_test_fr.txt \\\n",
        "--azunre True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqQ6x8Coxpgq"
      },
      "source": [
        "#### SacreBLEU Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEfwu_SPq61l"
      },
      "outputs": [],
      "source": [
        "!python /content/TW-FR-MT/MT_systems/evalution_scripts/get_sacrebleu.py \\\n",
        "twi-fr-google-translate \\\n",
        "/content/TW-FR-MT/TW_FR_EN_corpus/data/test/un_test_fr.txt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkrnJKUZizyd"
      },
      "source": [
        "TER Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqLW2AjiirOV"
      },
      "outputs": [],
      "source": [
        "!python /content/TW-FR-MT/MT_systems/evalution_scripts/ter.py \\\n",
        "twi-fr-google-translate \\\n",
        "/content/TW-FR-MT/TW_FR_EN_corpus/data/test/un_test_fr.txt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP4BEOMqpV2d"
      },
      "source": [
        "## OPUS Pivot Translation\n",
        "\n",
        "\n",
        "To perform pivot translation, you will need to fine-tune additional models.<br>\n",
        "You can alternatively download fine-tuned models from our project from Google [Drive](https://drive.google.com/drive/folders/13irIvPsqnryP_NJ5y6PneFKrQDJs5Qm6?usp=sharing).\n",
        "\n",
        "\n",
        "$<source>$ -> $<English>$ ->$<Target>$\n",
        "\n",
        "\n",
        "We will demonstrate pivot Twi -> English -> French translation.<br>\n",
        "In this tutorial, we use our fine-tuned models. To use pre-trained OPUS-MT models, pass the name of the OPUS-MT model as shown below.<br>\n",
        "\n",
        "For French -> English -> Twi using Pre-trained OPUS-MT models\n",
        "```\n",
        "!python /content/TW-FR-MT/MT_systems/opus/opus_pivot_translate.py \\\n",
        "Helsinki-NLP/opus-mt-fr-en \\ \n",
        "Helsinki-NLP/opus-mt-en-tw \\\n",
        "/content/TW-FR-MT/TW_FR_EN_corpus/data/test/test_fr.txt \\\n",
        "--to_console True\n",
        "\n",
        "```\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yXBWEggpQZu"
      },
      "outputs": [],
      "source": [
        "!python /content/TW-FR-MT/MT_systems/opus/opus_pivot_translate.py \\\n",
        "/content/drive/MyDrive/MT/OPUS-mt-tw-en-tuned \\\n",
        "/content/drive/MyDrive/MT/OPUS-mt-en-fr-tuned \\\n",
        "/content/TW-FR-MT/TW_FR_EN_corpus/data/test/test_tw.txt \\\n",
        "--to_console True"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}